Team P10 RETROSPECTIVE Sprint #4
=====================================

## PROCESS MEASURES 

### Macro statistics

- Number of stories committed vs done : 3/3
- Total points committed vs done : 34/34
- Nr of hours planned vs spent (as a team) :  /  


### Definition of Done
- Unit Tests passing
- Code review completed
- Working code present on VCS
- No Blocker sonar code smells
- No bugs on sonar
- End-to-End tests performed



### Detailed statistics

| Story  | # Tasks | Points | Hours est. | Hours actual |
|--------|---------|--------|------------|--------------|
| 0      |         |    -   |         |    |
| 1      |        |       |           |            |
| 2      |        |     |          |            |
| 3      |         |      |          |           |




- Hours per task (average, standard deviation) : 
- Total task estimation error ratio: sum of total hours estimation / sum of total hours spent from previous table : 

  
## QUALITY MEASURES 

- Unit Testing:
  - Total hours estimated : 
  - Total hours spent : 
  - Nr of automated unit test cases : 66 old + x new
  - Coverage  : 
- E2E testing:
  - Total hours estimated : 
  - Total hours spent : 
- Code review 
  - Total hours estimated : 
  - Total hours spent : 
- Technical Debt management:
  - Total hours estimated : 
  - Total hours spent : 
  - Hours estimated for remediation by SonarQube : 6h 
  - Hours estimated for remediation by SonarQube only for the selected and planned issues : 1h 50m (reduce replication, delete blocker code smells , reduce critical code smells, assert no bug present) 
  - Hours spent on remediation  : we spent x time to reduce duplications , minimize code smells and assert that there were no blocker code smells or bugs.
  - debt ratio (as reported by SonarQube under "Measures-Maintainability") :  %
  - rating for each quality characteristic reported in SonarQube under "Measures" (namely reliability, security, maintainability ) :
  <br>Reliability : A <br>Security : A
  <br>Maintainability : A
  
## ASSESSMENT

- What caused your errors in estimation (if any)? <br>
We underestimated the manage of the virtual clock, we were not able to complete the task related to it <br>Unit test required more time beacuse some people started approaching it for the first time <br> Some tasks required less time than expected thanks to reuse of code , for example to create page for product confirmation and order change<br>


- What lessons did you learn (both positive and negative) in this sprint? <br>
Meetings in presence are better than virtual ones<br>
Time is a difficult aspect to manage, to not be understimate and take in account since the beginning of the development<br>

- Which improvement goals set in the previous retrospective were you able to achieve? <br>


- Which ones you were not able to achieve? Why?<br> 
  We could improve testing now that we have more people involved

- Improvement goals for the next sprint and how to achieve them (technical tasks, team coordination, etc.) 
<br> We want to better manage our time<br>


- One thing you are proud of as a Team!!<br>
When we got a problem we go straight to a single and shared solution
